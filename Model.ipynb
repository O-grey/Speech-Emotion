{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Importing Models and Scores:\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score,classification_report,confusion_matrix,precision_score,recall_score,f1_score"
      ],
      "metadata": {
        "id": "6rDFAlWAvxhE"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(r'/content/mfcc_40_features_only.csv')\n",
        "df2=pd.read_csv(r'/content/drive/MyDrive/audios/csv files/Freq-Domain-mean-features.csv')"
      ],
      "metadata": {
        "id": "kXLc6Ra3v674"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Ensure both DataFrames have a common key (e.g., filepath or filename)\n",
        "# Let's assume the key is 'filepath' in both df and df2\n",
        "\n",
        "# 2. Select only the relevant columns from df2\n",
        "selected_cols = ['filepath', 'BER_Mean', 'Spec_Centroid_Mean', 'Spec_Bandwidth_Mean']\n",
        "df2_selected = df2[selected_cols]\n",
        "\n",
        "# 3. Merge into df on 'filepath'\n",
        "df = df.merge(df2_selected, on='filepath', how='left')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 790
        },
        "id": "_BDF0ONFv64e",
        "outputId": "bf6c70c0-fd53-4b5b-974c-a52746973664"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      filename  emotion intensity    modality  gender  \\\n",
              "0     03-01-01-01-02-01-22.wav  Neutral    Normal  Audio-Only  Female   \n",
              "1     03-01-01-01-01-02-22.wav  Neutral    Normal  Audio-Only  Female   \n",
              "2     03-01-01-01-01-01-22.wav  Neutral    Normal  Audio-Only  Female   \n",
              "3     03-01-01-01-02-02-22.wav  Neutral    Normal  Audio-Only  Female   \n",
              "4     03-01-03-02-02-01-22.wav    Happy    Strong  Audio-Only  Female   \n",
              "...                        ...      ...       ...         ...     ...   \n",
              "2447  03-02-06-02-02-01-02.wav  Fearful    Strong  Audio-Only  Female   \n",
              "2448  03-02-06-01-02-01-02.wav  Fearful    Normal  Audio-Only  Female   \n",
              "2449  03-02-06-01-02-02-02.wav  Fearful    Normal  Audio-Only  Female   \n",
              "2450  03-02-06-02-01-01-02.wav  Fearful    Strong  Audio-Only  Female   \n",
              "2451  03-02-06-02-02-02-02.wav  Fearful    Strong  Audio-Only  Female   \n",
              "\n",
              "      actor_id                                           filepath   AE_mean  \\\n",
              "0           22  /content/drive/MyDrive/audios/wav files/Audio_...  0.007719   \n",
              "1           22  /content/drive/MyDrive/audios/wav files/Audio_...  0.007135   \n",
              "2           22  /content/drive/MyDrive/audios/wav files/Audio_...  0.006430   \n",
              "3           22  /content/drive/MyDrive/audios/wav files/Audio_...  0.007372   \n",
              "4           22  /content/drive/MyDrive/audios/wav files/Audio_...  0.039155   \n",
              "...        ...                                                ...       ...   \n",
              "2447         2  /content/drive/MyDrive/audios/wav files/Audio_...  0.052375   \n",
              "2448         2  /content/drive/MyDrive/audios/wav files/Audio_...  0.032363   \n",
              "2449         2  /content/drive/MyDrive/audios/wav files/Audio_...  0.030873   \n",
              "2450         2  /content/drive/MyDrive/audios/wav files/Audio_...  0.050430   \n",
              "2451         2  /content/drive/MyDrive/audios/wav files/Audio_...  0.055686   \n",
              "\n",
              "      RMSE_mean  ZCR_mean  ...   MFCC_37   MFCC_38   MFCC_39   MFCC_40  \\\n",
              "0      0.002580  0.059296  ...  0.629421  1.542944  0.125471 -0.027604   \n",
              "1      0.002282  0.067220  ...  0.757751  0.020876 -0.642699 -0.046494   \n",
              "2      0.002092  0.061312  ...  0.610917  0.878997  0.091135 -0.332697   \n",
              "3      0.002385  0.072839  ...  0.382474  1.535111  0.098079  0.174156   \n",
              "4      0.013946  0.086826  ...  1.961565  0.304025 -2.015385 -1.509780   \n",
              "...         ...       ...  ...       ...       ...       ...       ...   \n",
              "2447   0.020592  0.086145  ... -5.350123 -0.636383  1.444936 -0.051213   \n",
              "2448   0.012334  0.075225  ... -5.684637 -0.136087  2.389726  1.795649   \n",
              "2449   0.012220  0.081032  ... -3.737191  0.607224  3.287630  2.869979   \n",
              "2450   0.019506  0.078261  ... -5.726693 -1.442012  1.422696  0.313033   \n",
              "2451   0.021416  0.080697  ... -3.510531  0.415554  1.541532 -0.725534   \n",
              "\n",
              "      BER_Mean_x  Spec_Centroid_Mean_x  Spec_Bandwidth_Mean_x  BER_Mean_y  \\\n",
              "0     344.622345           6392.194350            5549.157395  344.622345   \n",
              "1     201.883392           6383.553288            5614.825854  201.883392   \n",
              "2     305.614830           6345.728410            5558.905619  305.614830   \n",
              "3     239.593109           6488.189220            5592.395097  239.593109   \n",
              "4     149.006699           6789.160067            5660.422516  149.006699   \n",
              "...          ...                   ...                    ...         ...   \n",
              "2447  453.503876           4737.180648            4455.844067  453.503876   \n",
              "2448  507.715363           5319.634513            4577.900375  507.715363   \n",
              "2449  624.258479           4823.505866            4196.330641  624.258479   \n",
              "2450  406.675842           4909.359382            4300.577625  406.675842   \n",
              "2451  576.892883           4997.273571            4491.391884  576.892883   \n",
              "\n",
              "      Spec_Centroid_Mean_y  Spec_Bandwidth_Mean_y  \n",
              "0              6392.194350            5549.157395  \n",
              "1              6383.553288            5614.825854  \n",
              "2              6345.728410            5558.905619  \n",
              "3              6488.189220            5592.395097  \n",
              "4              6789.160067            5660.422516  \n",
              "...                    ...                    ...  \n",
              "2447           4737.180648            4455.844067  \n",
              "2448           5319.634513            4577.900375  \n",
              "2449           4823.505866            4196.330641  \n",
              "2450           4909.359382            4300.577625  \n",
              "2451           4997.273571            4491.391884  \n",
              "\n",
              "[2452 rows x 184 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-06982365-607a-4ed4-98a8-ce625265f7aa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>emotion</th>\n",
              "      <th>intensity</th>\n",
              "      <th>modality</th>\n",
              "      <th>gender</th>\n",
              "      <th>actor_id</th>\n",
              "      <th>filepath</th>\n",
              "      <th>AE_mean</th>\n",
              "      <th>RMSE_mean</th>\n",
              "      <th>ZCR_mean</th>\n",
              "      <th>...</th>\n",
              "      <th>MFCC_37</th>\n",
              "      <th>MFCC_38</th>\n",
              "      <th>MFCC_39</th>\n",
              "      <th>MFCC_40</th>\n",
              "      <th>BER_Mean_x</th>\n",
              "      <th>Spec_Centroid_Mean_x</th>\n",
              "      <th>Spec_Bandwidth_Mean_x</th>\n",
              "      <th>BER_Mean_y</th>\n",
              "      <th>Spec_Centroid_Mean_y</th>\n",
              "      <th>Spec_Bandwidth_Mean_y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>03-01-01-01-02-01-22.wav</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Audio-Only</td>\n",
              "      <td>Female</td>\n",
              "      <td>22</td>\n",
              "      <td>/content/drive/MyDrive/audios/wav files/Audio_...</td>\n",
              "      <td>0.007719</td>\n",
              "      <td>0.002580</td>\n",
              "      <td>0.059296</td>\n",
              "      <td>...</td>\n",
              "      <td>0.629421</td>\n",
              "      <td>1.542944</td>\n",
              "      <td>0.125471</td>\n",
              "      <td>-0.027604</td>\n",
              "      <td>344.622345</td>\n",
              "      <td>6392.194350</td>\n",
              "      <td>5549.157395</td>\n",
              "      <td>344.622345</td>\n",
              "      <td>6392.194350</td>\n",
              "      <td>5549.157395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>03-01-01-01-01-02-22.wav</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Audio-Only</td>\n",
              "      <td>Female</td>\n",
              "      <td>22</td>\n",
              "      <td>/content/drive/MyDrive/audios/wav files/Audio_...</td>\n",
              "      <td>0.007135</td>\n",
              "      <td>0.002282</td>\n",
              "      <td>0.067220</td>\n",
              "      <td>...</td>\n",
              "      <td>0.757751</td>\n",
              "      <td>0.020876</td>\n",
              "      <td>-0.642699</td>\n",
              "      <td>-0.046494</td>\n",
              "      <td>201.883392</td>\n",
              "      <td>6383.553288</td>\n",
              "      <td>5614.825854</td>\n",
              "      <td>201.883392</td>\n",
              "      <td>6383.553288</td>\n",
              "      <td>5614.825854</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>03-01-01-01-01-01-22.wav</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Audio-Only</td>\n",
              "      <td>Female</td>\n",
              "      <td>22</td>\n",
              "      <td>/content/drive/MyDrive/audios/wav files/Audio_...</td>\n",
              "      <td>0.006430</td>\n",
              "      <td>0.002092</td>\n",
              "      <td>0.061312</td>\n",
              "      <td>...</td>\n",
              "      <td>0.610917</td>\n",
              "      <td>0.878997</td>\n",
              "      <td>0.091135</td>\n",
              "      <td>-0.332697</td>\n",
              "      <td>305.614830</td>\n",
              "      <td>6345.728410</td>\n",
              "      <td>5558.905619</td>\n",
              "      <td>305.614830</td>\n",
              "      <td>6345.728410</td>\n",
              "      <td>5558.905619</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>03-01-01-01-02-02-22.wav</td>\n",
              "      <td>Neutral</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Audio-Only</td>\n",
              "      <td>Female</td>\n",
              "      <td>22</td>\n",
              "      <td>/content/drive/MyDrive/audios/wav files/Audio_...</td>\n",
              "      <td>0.007372</td>\n",
              "      <td>0.002385</td>\n",
              "      <td>0.072839</td>\n",
              "      <td>...</td>\n",
              "      <td>0.382474</td>\n",
              "      <td>1.535111</td>\n",
              "      <td>0.098079</td>\n",
              "      <td>0.174156</td>\n",
              "      <td>239.593109</td>\n",
              "      <td>6488.189220</td>\n",
              "      <td>5592.395097</td>\n",
              "      <td>239.593109</td>\n",
              "      <td>6488.189220</td>\n",
              "      <td>5592.395097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>03-01-03-02-02-01-22.wav</td>\n",
              "      <td>Happy</td>\n",
              "      <td>Strong</td>\n",
              "      <td>Audio-Only</td>\n",
              "      <td>Female</td>\n",
              "      <td>22</td>\n",
              "      <td>/content/drive/MyDrive/audios/wav files/Audio_...</td>\n",
              "      <td>0.039155</td>\n",
              "      <td>0.013946</td>\n",
              "      <td>0.086826</td>\n",
              "      <td>...</td>\n",
              "      <td>1.961565</td>\n",
              "      <td>0.304025</td>\n",
              "      <td>-2.015385</td>\n",
              "      <td>-1.509780</td>\n",
              "      <td>149.006699</td>\n",
              "      <td>6789.160067</td>\n",
              "      <td>5660.422516</td>\n",
              "      <td>149.006699</td>\n",
              "      <td>6789.160067</td>\n",
              "      <td>5660.422516</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2447</th>\n",
              "      <td>03-02-06-02-02-01-02.wav</td>\n",
              "      <td>Fearful</td>\n",
              "      <td>Strong</td>\n",
              "      <td>Audio-Only</td>\n",
              "      <td>Female</td>\n",
              "      <td>2</td>\n",
              "      <td>/content/drive/MyDrive/audios/wav files/Audio_...</td>\n",
              "      <td>0.052375</td>\n",
              "      <td>0.020592</td>\n",
              "      <td>0.086145</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.350123</td>\n",
              "      <td>-0.636383</td>\n",
              "      <td>1.444936</td>\n",
              "      <td>-0.051213</td>\n",
              "      <td>453.503876</td>\n",
              "      <td>4737.180648</td>\n",
              "      <td>4455.844067</td>\n",
              "      <td>453.503876</td>\n",
              "      <td>4737.180648</td>\n",
              "      <td>4455.844067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2448</th>\n",
              "      <td>03-02-06-01-02-01-02.wav</td>\n",
              "      <td>Fearful</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Audio-Only</td>\n",
              "      <td>Female</td>\n",
              "      <td>2</td>\n",
              "      <td>/content/drive/MyDrive/audios/wav files/Audio_...</td>\n",
              "      <td>0.032363</td>\n",
              "      <td>0.012334</td>\n",
              "      <td>0.075225</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.684637</td>\n",
              "      <td>-0.136087</td>\n",
              "      <td>2.389726</td>\n",
              "      <td>1.795649</td>\n",
              "      <td>507.715363</td>\n",
              "      <td>5319.634513</td>\n",
              "      <td>4577.900375</td>\n",
              "      <td>507.715363</td>\n",
              "      <td>5319.634513</td>\n",
              "      <td>4577.900375</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2449</th>\n",
              "      <td>03-02-06-01-02-02-02.wav</td>\n",
              "      <td>Fearful</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Audio-Only</td>\n",
              "      <td>Female</td>\n",
              "      <td>2</td>\n",
              "      <td>/content/drive/MyDrive/audios/wav files/Audio_...</td>\n",
              "      <td>0.030873</td>\n",
              "      <td>0.012220</td>\n",
              "      <td>0.081032</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.737191</td>\n",
              "      <td>0.607224</td>\n",
              "      <td>3.287630</td>\n",
              "      <td>2.869979</td>\n",
              "      <td>624.258479</td>\n",
              "      <td>4823.505866</td>\n",
              "      <td>4196.330641</td>\n",
              "      <td>624.258479</td>\n",
              "      <td>4823.505866</td>\n",
              "      <td>4196.330641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2450</th>\n",
              "      <td>03-02-06-02-01-01-02.wav</td>\n",
              "      <td>Fearful</td>\n",
              "      <td>Strong</td>\n",
              "      <td>Audio-Only</td>\n",
              "      <td>Female</td>\n",
              "      <td>2</td>\n",
              "      <td>/content/drive/MyDrive/audios/wav files/Audio_...</td>\n",
              "      <td>0.050430</td>\n",
              "      <td>0.019506</td>\n",
              "      <td>0.078261</td>\n",
              "      <td>...</td>\n",
              "      <td>-5.726693</td>\n",
              "      <td>-1.442012</td>\n",
              "      <td>1.422696</td>\n",
              "      <td>0.313033</td>\n",
              "      <td>406.675842</td>\n",
              "      <td>4909.359382</td>\n",
              "      <td>4300.577625</td>\n",
              "      <td>406.675842</td>\n",
              "      <td>4909.359382</td>\n",
              "      <td>4300.577625</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2451</th>\n",
              "      <td>03-02-06-02-02-02-02.wav</td>\n",
              "      <td>Fearful</td>\n",
              "      <td>Strong</td>\n",
              "      <td>Audio-Only</td>\n",
              "      <td>Female</td>\n",
              "      <td>2</td>\n",
              "      <td>/content/drive/MyDrive/audios/wav files/Audio_...</td>\n",
              "      <td>0.055686</td>\n",
              "      <td>0.021416</td>\n",
              "      <td>0.080697</td>\n",
              "      <td>...</td>\n",
              "      <td>-3.510531</td>\n",
              "      <td>0.415554</td>\n",
              "      <td>1.541532</td>\n",
              "      <td>-0.725534</td>\n",
              "      <td>576.892883</td>\n",
              "      <td>4997.273571</td>\n",
              "      <td>4491.391884</td>\n",
              "      <td>576.892883</td>\n",
              "      <td>4997.273571</td>\n",
              "      <td>4491.391884</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2452 rows × 184 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06982365-607a-4ed4-98a8-ce625265f7aa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-06982365-607a-4ed4-98a8-ce625265f7aa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-06982365-607a-4ed4-98a8-ce625265f7aa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7a9dd38b-2401-452d-a170-c17145aaacb6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7a9dd38b-2401-452d-a170-c17145aaacb6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7a9dd38b-2401-452d-a170-c17145aaacb6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_086df079-8813-499b-a5e9-a728c60584d8\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_086df079-8813-499b-a5e9-a728c60584d8 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['intensity'].info()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaEkTbJcbpN1",
        "outputId": "33e85989-c580-4280-ada9-ae9517a161d2"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "RangeIndex: 2452 entries, 0 to 2451\n",
            "Series name: intensity\n",
            "Non-Null Count  Dtype \n",
            "--------------  ----- \n",
            "2452 non-null   object\n",
            "dtypes: object(1)\n",
            "memory usage: 19.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Remove rows where emotion is 'Neutral' or 'Surprised'\n",
        "df = df[~df['emotion'].isin(['Surprised'])].reset_index(drop=True)\n",
        "\n",
        "print(f\"Original dataset size: {df.shape[0]} rows\")\n",
        "print(f\"Filtered dataset size: {df.shape[0]} rows\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqYVOt32wpxm",
        "outputId": "c2d45096-63e1-4543-d0d0-bc9702453679"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original dataset size: 2260 rows\n",
            "Filtered dataset size: 2260 rows\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Yuh7OjDQuTz",
        "outputId": "d9c70d9d-0999-4e37-b9cb-10c3c02cfa10"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2260 entries, 0 to 2259\n",
            "Columns: 184 entries, filename to Spec_Bandwidth_Mean_y\n",
            "dtypes: float64(177), int64(1), object(6)\n",
            "memory usage: 3.2+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Trying ANN as base model."
      ],
      "metadata": {
        "id": "ZPjT_22AxJuB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import joblib\n",
        "\n",
        "# 1. Drop unused columns\n",
        "df_model = df.drop(columns=['filename', 'filepath', 'actor_id', 'modality'])\n",
        "\n",
        "# 2. Label encode categorical columns and save encoders\n",
        "le_gender = LabelEncoder()\n",
        "le_intensity = LabelEncoder()\n",
        "le_emotion = LabelEncoder()\n",
        "\n",
        "df_model['gender'] = le_gender.fit_transform(df_model['gender'])\n",
        "df_model['intensity'] = le_intensity.fit_transform(df_model['intensity'])\n",
        "df_model['emotion'] = le_emotion.fit_transform(df_model['emotion'])\n",
        "\n",
        "# Save encoders for inference later\n",
        "joblib.dump(le_gender, \"le_genderii.pkl\")\n",
        "joblib.dump(le_intensity, \"le_intensityii.pkl\")\n",
        "joblib.dump(le_emotion, \"le_emotionii.pkl\")\n",
        "\n",
        "# 3. Split X and y\n",
        "X = df_model.drop(columns=['emotion', 'AE_mean', 'RMSE_mean', 'ZCR_mean'])\n",
        "y = df_model['emotion']\n",
        "\n",
        "# 4. Save feature column order\n",
        "feature_order = X.columns.tolist()\n",
        "joblib.dump(feature_order, \"feature_order.pkl\")\n",
        "\n",
        "# 5. Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# 6. Scale only float columns\n",
        "float_cols = X_train.select_dtypes(include=['float32', 'float64', 'int64']).columns.difference(['gender', 'intensity'])\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = X_train.copy()\n",
        "X_test_scaled = X_test.copy()\n",
        "\n",
        "X_train_scaled[float_cols] = scaler.fit_transform(X_train[float_cols])\n",
        "X_test_scaled[float_cols] = scaler.transform(X_test[float_cols])\n",
        "\n",
        "# Save scaler\n",
        "joblib.dump(scaler, \"scalerii.pkl\")\n",
        "\n",
        "# 7. Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_bal, y_train_bal = smote.fit_resample(X_train_scaled, y_train)\n",
        "\n",
        "print(\"Training preprocessing complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3wwHFoSckkZ-",
        "outputId": "a4789fe8-4f65-4300-cdc0-c43a54555453"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training preprocessing complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Show class distribution after SMOTE\n",
        "import pandas as pd\n",
        "\n",
        "class_counts = pd.Series(y_train_bal).value_counts()\n",
        "print(\"Class distribution after SMOTE:\")\n",
        "print(class_counts.sort_index())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GqG_Pqk30ZF7",
        "outputId": "3ddb679c-2678-4ead-ee7e-77074d095288"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class distribution after SMOTE:\n",
            "emotion\n",
            "0    301\n",
            "1    301\n",
            "2    301\n",
            "3    301\n",
            "4    301\n",
            "5    301\n",
            "6    301\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Build ANN\n",
        "model = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train_bal.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(len(le_emotion.classes_), activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train\n",
        "model.fit(X_train_bal, y_train_bal, epochs=250, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate\n",
        "y_pred_probs = model.predict(X_test_scaled)\n",
        "y_pred = np.argmax(y_pred_probs, axis=1)\n",
        "\n",
        "print(classification_report(y_test, y_pred, target_names=le_emotion.classes_))\n",
        "\n",
        "# Save model\n",
        "model.save(\"emotion_ann_modelii.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLti7kMCkkX2",
        "outputId": "1c84545a-1984-42c6-8ebc-29a5a37a1e37"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 10ms/step - accuracy: 0.2244 - loss: 1.8952 - val_accuracy: 0.1019 - val_loss: 1.9367\n",
            "Epoch 2/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3006 - loss: 1.7174 - val_accuracy: 0.2085 - val_loss: 1.7421\n",
            "Epoch 3/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3484 - loss: 1.5957 - val_accuracy: 0.1943 - val_loss: 1.6701\n",
            "Epoch 4/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3974 - loss: 1.4933 - val_accuracy: 0.2938 - val_loss: 1.5571\n",
            "Epoch 5/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4633 - loss: 1.3855 - val_accuracy: 0.3697 - val_loss: 1.4329\n",
            "Epoch 6/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4861 - loss: 1.3425 - val_accuracy: 0.4573 - val_loss: 1.4246\n",
            "Epoch 7/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.4910 - loss: 1.2734 - val_accuracy: 0.5711 - val_loss: 1.2094\n",
            "Epoch 8/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5001 - loss: 1.2421 - val_accuracy: 0.5877 - val_loss: 1.1421\n",
            "Epoch 9/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5480 - loss: 1.1772 - val_accuracy: 0.5829 - val_loss: 1.1049\n",
            "Epoch 10/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.5730 - loss: 1.1079 - val_accuracy: 0.6682 - val_loss: 1.0275\n",
            "Epoch 11/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5765 - loss: 1.0747 - val_accuracy: 0.6209 - val_loss: 1.0382\n",
            "Epoch 12/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5773 - loss: 1.1384 - val_accuracy: 0.6351 - val_loss: 1.0060\n",
            "Epoch 13/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.5910 - loss: 1.0791 - val_accuracy: 0.6043 - val_loss: 1.0417\n",
            "Epoch 14/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.5757 - loss: 1.0687 - val_accuracy: 0.6825 - val_loss: 0.8805\n",
            "Epoch 15/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6124 - loss: 1.0391 - val_accuracy: 0.6351 - val_loss: 0.9663\n",
            "Epoch 16/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6179 - loss: 0.9749 - val_accuracy: 0.6374 - val_loss: 0.8769\n",
            "Epoch 17/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6180 - loss: 0.9812 - val_accuracy: 0.6730 - val_loss: 0.8151\n",
            "Epoch 18/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6209 - loss: 0.9494 - val_accuracy: 0.6209 - val_loss: 0.8799\n",
            "Epoch 19/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6564 - loss: 0.9549 - val_accuracy: 0.6991 - val_loss: 0.8159\n",
            "Epoch 20/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6776 - loss: 0.8772 - val_accuracy: 0.6825 - val_loss: 0.8068\n",
            "Epoch 21/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6778 - loss: 0.8742 - val_accuracy: 0.6469 - val_loss: 0.8111\n",
            "Epoch 22/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6569 - loss: 0.8899 - val_accuracy: 0.6967 - val_loss: 0.7105\n",
            "Epoch 23/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6926 - loss: 0.8316 - val_accuracy: 0.6967 - val_loss: 0.7587\n",
            "Epoch 24/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6676 - loss: 0.8442 - val_accuracy: 0.7062 - val_loss: 0.7299\n",
            "Epoch 25/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6782 - loss: 0.8240 - val_accuracy: 0.7417 - val_loss: 0.6750\n",
            "Epoch 26/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6540 - loss: 0.8635 - val_accuracy: 0.7536 - val_loss: 0.6948\n",
            "Epoch 27/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7001 - loss: 0.7571 - val_accuracy: 0.7251 - val_loss: 0.7630\n",
            "Epoch 28/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7070 - loss: 0.7955 - val_accuracy: 0.7204 - val_loss: 0.7195\n",
            "Epoch 29/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6919 - loss: 0.8028 - val_accuracy: 0.7322 - val_loss: 0.6837\n",
            "Epoch 30/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.6962 - loss: 0.7549 - val_accuracy: 0.7085 - val_loss: 0.7186\n",
            "Epoch 31/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7047 - loss: 0.7892 - val_accuracy: 0.7393 - val_loss: 0.6529\n",
            "Epoch 32/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7370 - loss: 0.7216 - val_accuracy: 0.7607 - val_loss: 0.6379\n",
            "Epoch 33/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7110 - loss: 0.7566 - val_accuracy: 0.7133 - val_loss: 0.6822\n",
            "Epoch 34/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7519 - loss: 0.6805 - val_accuracy: 0.7085 - val_loss: 0.6855\n",
            "Epoch 35/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7447 - loss: 0.6850 - val_accuracy: 0.7393 - val_loss: 0.5846\n",
            "Epoch 36/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7407 - loss: 0.7070 - val_accuracy: 0.7583 - val_loss: 0.6000\n",
            "Epoch 37/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7327 - loss: 0.6937 - val_accuracy: 0.7014 - val_loss: 0.7102\n",
            "Epoch 38/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7195 - loss: 0.7293 - val_accuracy: 0.7607 - val_loss: 0.5946\n",
            "Epoch 39/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7462 - loss: 0.6715 - val_accuracy: 0.7630 - val_loss: 0.5761\n",
            "Epoch 40/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7515 - loss: 0.6550 - val_accuracy: 0.7630 - val_loss: 0.5830\n",
            "Epoch 41/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7556 - loss: 0.6136 - val_accuracy: 0.7725 - val_loss: 0.5372\n",
            "Epoch 42/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7584 - loss: 0.6358 - val_accuracy: 0.7607 - val_loss: 0.5695\n",
            "Epoch 43/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7511 - loss: 0.6493 - val_accuracy: 0.7867 - val_loss: 0.5498\n",
            "Epoch 44/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7494 - loss: 0.6660 - val_accuracy: 0.7678 - val_loss: 0.6092\n",
            "Epoch 45/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7664 - loss: 0.6240 - val_accuracy: 0.7938 - val_loss: 0.5266\n",
            "Epoch 46/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7576 - loss: 0.6215 - val_accuracy: 0.7701 - val_loss: 0.5671\n",
            "Epoch 47/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7528 - loss: 0.6543 - val_accuracy: 0.7109 - val_loss: 0.6919\n",
            "Epoch 48/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.7836 - loss: 0.6069 - val_accuracy: 0.7512 - val_loss: 0.5522\n",
            "Epoch 49/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7655 - loss: 0.6078 - val_accuracy: 0.7701 - val_loss: 0.5829\n",
            "Epoch 50/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7618 - loss: 0.6303 - val_accuracy: 0.7133 - val_loss: 0.6777\n",
            "Epoch 51/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7643 - loss: 0.6289 - val_accuracy: 0.7938 - val_loss: 0.5671\n",
            "Epoch 52/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7739 - loss: 0.5884 - val_accuracy: 0.8104 - val_loss: 0.4710\n",
            "Epoch 53/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7742 - loss: 0.6190 - val_accuracy: 0.7559 - val_loss: 0.5766\n",
            "Epoch 54/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8005 - loss: 0.5352 - val_accuracy: 0.8507 - val_loss: 0.4622\n",
            "Epoch 55/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7886 - loss: 0.5313 - val_accuracy: 0.7796 - val_loss: 0.5061\n",
            "Epoch 56/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7808 - loss: 0.5749 - val_accuracy: 0.7820 - val_loss: 0.5282\n",
            "Epoch 57/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8060 - loss: 0.5512 - val_accuracy: 0.7678 - val_loss: 0.4908\n",
            "Epoch 58/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7820 - loss: 0.5450 - val_accuracy: 0.8175 - val_loss: 0.4611\n",
            "Epoch 59/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7994 - loss: 0.5490 - val_accuracy: 0.7417 - val_loss: 0.5836\n",
            "Epoch 60/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7957 - loss: 0.5629 - val_accuracy: 0.8033 - val_loss: 0.4805\n",
            "Epoch 61/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8153 - loss: 0.4770 - val_accuracy: 0.7559 - val_loss: 0.6009\n",
            "Epoch 62/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7772 - loss: 0.5638 - val_accuracy: 0.7796 - val_loss: 0.4925\n",
            "Epoch 63/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7782 - loss: 0.5873 - val_accuracy: 0.7938 - val_loss: 0.5225\n",
            "Epoch 64/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8142 - loss: 0.5141 - val_accuracy: 0.7962 - val_loss: 0.4960\n",
            "Epoch 65/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7937 - loss: 0.5903 - val_accuracy: 0.8768 - val_loss: 0.4386\n",
            "Epoch 66/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8185 - loss: 0.4798 - val_accuracy: 0.8057 - val_loss: 0.4810\n",
            "Epoch 67/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8084 - loss: 0.5473 - val_accuracy: 0.8294 - val_loss: 0.4406\n",
            "Epoch 68/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7951 - loss: 0.5017 - val_accuracy: 0.8341 - val_loss: 0.4340\n",
            "Epoch 69/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8301 - loss: 0.4595 - val_accuracy: 0.8175 - val_loss: 0.4792\n",
            "Epoch 70/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8285 - loss: 0.4765 - val_accuracy: 0.8081 - val_loss: 0.4668\n",
            "Epoch 71/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8119 - loss: 0.5109 - val_accuracy: 0.8057 - val_loss: 0.4639\n",
            "Epoch 72/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8026 - loss: 0.5351 - val_accuracy: 0.8246 - val_loss: 0.4831\n",
            "Epoch 73/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8156 - loss: 0.4755 - val_accuracy: 0.8697 - val_loss: 0.4420\n",
            "Epoch 74/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8384 - loss: 0.4581 - val_accuracy: 0.7820 - val_loss: 0.4889\n",
            "Epoch 75/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8351 - loss: 0.4753 - val_accuracy: 0.7938 - val_loss: 0.4809\n",
            "Epoch 76/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8321 - loss: 0.4955 - val_accuracy: 0.8626 - val_loss: 0.4391\n",
            "Epoch 77/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8231 - loss: 0.4596 - val_accuracy: 0.8199 - val_loss: 0.4609\n",
            "Epoch 78/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8163 - loss: 0.4799 - val_accuracy: 0.8578 - val_loss: 0.4027\n",
            "Epoch 79/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8477 - loss: 0.4261 - val_accuracy: 0.8389 - val_loss: 0.4300\n",
            "Epoch 80/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8316 - loss: 0.4510 - val_accuracy: 0.8246 - val_loss: 0.4515\n",
            "Epoch 81/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8271 - loss: 0.4705 - val_accuracy: 0.8483 - val_loss: 0.4453\n",
            "Epoch 82/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8232 - loss: 0.4625 - val_accuracy: 0.8057 - val_loss: 0.4410\n",
            "Epoch 83/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8031 - loss: 0.4847 - val_accuracy: 0.8294 - val_loss: 0.4891\n",
            "Epoch 84/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8086 - loss: 0.4873 - val_accuracy: 0.8199 - val_loss: 0.4396\n",
            "Epoch 85/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8440 - loss: 0.4180 - val_accuracy: 0.8057 - val_loss: 0.5102\n",
            "Epoch 86/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8223 - loss: 0.4663 - val_accuracy: 0.8318 - val_loss: 0.4234\n",
            "Epoch 87/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8456 - loss: 0.4266 - val_accuracy: 0.8365 - val_loss: 0.4828\n",
            "Epoch 88/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8250 - loss: 0.4666 - val_accuracy: 0.8673 - val_loss: 0.4418\n",
            "Epoch 89/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8432 - loss: 0.4185 - val_accuracy: 0.8744 - val_loss: 0.4200\n",
            "Epoch 90/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8465 - loss: 0.4040 - val_accuracy: 0.8483 - val_loss: 0.4290\n",
            "Epoch 91/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8493 - loss: 0.4186 - val_accuracy: 0.8483 - val_loss: 0.4312\n",
            "Epoch 92/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8423 - loss: 0.4539 - val_accuracy: 0.8815 - val_loss: 0.3920\n",
            "Epoch 93/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8149 - loss: 0.4988 - val_accuracy: 0.8152 - val_loss: 0.4366\n",
            "Epoch 94/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8596 - loss: 0.4136 - val_accuracy: 0.8483 - val_loss: 0.4296\n",
            "Epoch 95/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8434 - loss: 0.4071 - val_accuracy: 0.8246 - val_loss: 0.4417\n",
            "Epoch 96/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8501 - loss: 0.4067 - val_accuracy: 0.8602 - val_loss: 0.4191\n",
            "Epoch 97/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8436 - loss: 0.4301 - val_accuracy: 0.8270 - val_loss: 0.4278\n",
            "Epoch 98/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8525 - loss: 0.4167 - val_accuracy: 0.8460 - val_loss: 0.4314\n",
            "Epoch 99/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8444 - loss: 0.4283 - val_accuracy: 0.8578 - val_loss: 0.3962\n",
            "Epoch 100/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8529 - loss: 0.4214 - val_accuracy: 0.8246 - val_loss: 0.4032\n",
            "Epoch 101/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8503 - loss: 0.4067 - val_accuracy: 0.8910 - val_loss: 0.3541\n",
            "Epoch 102/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8543 - loss: 0.3933 - val_accuracy: 0.8626 - val_loss: 0.3946\n",
            "Epoch 103/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8618 - loss: 0.4097 - val_accuracy: 0.8199 - val_loss: 0.4293\n",
            "Epoch 104/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8272 - loss: 0.4256 - val_accuracy: 0.8531 - val_loss: 0.3961\n",
            "Epoch 105/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8379 - loss: 0.4074 - val_accuracy: 0.8886 - val_loss: 0.3848\n",
            "Epoch 106/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8577 - loss: 0.3854 - val_accuracy: 0.8673 - val_loss: 0.3919\n",
            "Epoch 107/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8406 - loss: 0.4168 - val_accuracy: 0.8910 - val_loss: 0.3545\n",
            "Epoch 108/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8730 - loss: 0.3519 - val_accuracy: 0.8886 - val_loss: 0.3611\n",
            "Epoch 109/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8751 - loss: 0.3789 - val_accuracy: 0.7773 - val_loss: 0.5570\n",
            "Epoch 110/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8610 - loss: 0.4339 - val_accuracy: 0.8602 - val_loss: 0.3961\n",
            "Epoch 111/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8571 - loss: 0.3934 - val_accuracy: 0.8673 - val_loss: 0.3721\n",
            "Epoch 112/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8686 - loss: 0.3761 - val_accuracy: 0.8886 - val_loss: 0.3475\n",
            "Epoch 113/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8672 - loss: 0.3384 - val_accuracy: 0.8934 - val_loss: 0.3496\n",
            "Epoch 114/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8710 - loss: 0.3749 - val_accuracy: 0.8507 - val_loss: 0.3763\n",
            "Epoch 115/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8319 - loss: 0.4922 - val_accuracy: 0.8697 - val_loss: 0.3867\n",
            "Epoch 116/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8479 - loss: 0.4173 - val_accuracy: 0.8768 - val_loss: 0.3667\n",
            "Epoch 117/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8772 - loss: 0.3598 - val_accuracy: 0.8720 - val_loss: 0.3952\n",
            "Epoch 118/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8447 - loss: 0.4012 - val_accuracy: 0.8697 - val_loss: 0.4133\n",
            "Epoch 119/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8456 - loss: 0.3801 - val_accuracy: 0.8578 - val_loss: 0.4019\n",
            "Epoch 120/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8502 - loss: 0.3944 - val_accuracy: 0.8697 - val_loss: 0.3817\n",
            "Epoch 121/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8691 - loss: 0.3396 - val_accuracy: 0.8934 - val_loss: 0.3395\n",
            "Epoch 122/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8568 - loss: 0.3828 - val_accuracy: 0.9052 - val_loss: 0.3295\n",
            "Epoch 123/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8581 - loss: 0.3851 - val_accuracy: 0.8578 - val_loss: 0.3479\n",
            "Epoch 124/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8925 - loss: 0.2986 - val_accuracy: 0.8555 - val_loss: 0.3649\n",
            "Epoch 125/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8687 - loss: 0.3462 - val_accuracy: 0.8602 - val_loss: 0.3910\n",
            "Epoch 126/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8741 - loss: 0.3627 - val_accuracy: 0.9005 - val_loss: 0.3350\n",
            "Epoch 127/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8811 - loss: 0.3246 - val_accuracy: 0.8246 - val_loss: 0.3866\n",
            "Epoch 128/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8742 - loss: 0.3769 - val_accuracy: 0.8436 - val_loss: 0.3528\n",
            "Epoch 129/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8815 - loss: 0.3314 - val_accuracy: 0.9194 - val_loss: 0.3004\n",
            "Epoch 130/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8814 - loss: 0.3230 - val_accuracy: 0.9005 - val_loss: 0.3055\n",
            "Epoch 131/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8656 - loss: 0.3738 - val_accuracy: 0.8815 - val_loss: 0.3444\n",
            "Epoch 132/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8592 - loss: 0.3690 - val_accuracy: 0.9005 - val_loss: 0.3202\n",
            "Epoch 133/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8794 - loss: 0.3313 - val_accuracy: 0.8531 - val_loss: 0.3722\n",
            "Epoch 134/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8834 - loss: 0.3087 - val_accuracy: 0.8507 - val_loss: 0.3722\n",
            "Epoch 135/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8737 - loss: 0.3539 - val_accuracy: 0.9052 - val_loss: 0.3419\n",
            "Epoch 136/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9077 - loss: 0.2881 - val_accuracy: 0.8341 - val_loss: 0.3867\n",
            "Epoch 137/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8777 - loss: 0.3259 - val_accuracy: 0.8839 - val_loss: 0.3141\n",
            "Epoch 138/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8858 - loss: 0.3246 - val_accuracy: 0.8839 - val_loss: 0.3745\n",
            "Epoch 139/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8666 - loss: 0.3658 - val_accuracy: 0.8602 - val_loss: 0.3636\n",
            "Epoch 140/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8904 - loss: 0.3011 - val_accuracy: 0.8649 - val_loss: 0.4084\n",
            "Epoch 141/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8802 - loss: 0.3486 - val_accuracy: 0.9194 - val_loss: 0.3087\n",
            "Epoch 142/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8641 - loss: 0.3614 - val_accuracy: 0.8768 - val_loss: 0.3526\n",
            "Epoch 143/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8785 - loss: 0.3379 - val_accuracy: 0.8531 - val_loss: 0.3614\n",
            "Epoch 144/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8879 - loss: 0.3602 - val_accuracy: 0.9005 - val_loss: 0.3020\n",
            "Epoch 145/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8904 - loss: 0.2885 - val_accuracy: 0.8673 - val_loss: 0.3588\n",
            "Epoch 146/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8972 - loss: 0.2901 - val_accuracy: 0.8910 - val_loss: 0.3350\n",
            "Epoch 147/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9011 - loss: 0.3050 - val_accuracy: 0.8531 - val_loss: 0.3757\n",
            "Epoch 148/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8814 - loss: 0.3380 - val_accuracy: 0.8483 - val_loss: 0.3647\n",
            "Epoch 149/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8849 - loss: 0.3310 - val_accuracy: 0.8863 - val_loss: 0.3297\n",
            "Epoch 150/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8848 - loss: 0.2950 - val_accuracy: 0.8507 - val_loss: 0.3528\n",
            "Epoch 151/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8817 - loss: 0.3091 - val_accuracy: 0.8791 - val_loss: 0.3511\n",
            "Epoch 152/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8948 - loss: 0.2981 - val_accuracy: 0.8626 - val_loss: 0.3529\n",
            "Epoch 153/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8970 - loss: 0.2771 - val_accuracy: 0.8720 - val_loss: 0.3740\n",
            "Epoch 154/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8825 - loss: 0.3126 - val_accuracy: 0.8649 - val_loss: 0.4167\n",
            "Epoch 155/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8808 - loss: 0.3238 - val_accuracy: 0.9028 - val_loss: 0.3428\n",
            "Epoch 156/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8873 - loss: 0.3348 - val_accuracy: 0.8957 - val_loss: 0.3131\n",
            "Epoch 157/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8656 - loss: 0.3387 - val_accuracy: 0.8910 - val_loss: 0.3280\n",
            "Epoch 158/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8922 - loss: 0.2943 - val_accuracy: 0.8531 - val_loss: 0.3951\n",
            "Epoch 159/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8770 - loss: 0.3604 - val_accuracy: 0.8981 - val_loss: 0.3220\n",
            "Epoch 160/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8928 - loss: 0.2928 - val_accuracy: 0.9100 - val_loss: 0.3118\n",
            "Epoch 161/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8987 - loss: 0.2890 - val_accuracy: 0.8507 - val_loss: 0.4196\n",
            "Epoch 162/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8850 - loss: 0.3263 - val_accuracy: 0.9052 - val_loss: 0.2998\n",
            "Epoch 163/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.8998 - loss: 0.2801 - val_accuracy: 0.8460 - val_loss: 0.3805\n",
            "Epoch 164/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8962 - loss: 0.3124 - val_accuracy: 0.9028 - val_loss: 0.2982\n",
            "Epoch 165/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9050 - loss: 0.2648 - val_accuracy: 0.8412 - val_loss: 0.3675\n",
            "Epoch 166/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9037 - loss: 0.2779 - val_accuracy: 0.9242 - val_loss: 0.3092\n",
            "Epoch 167/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8798 - loss: 0.3328 - val_accuracy: 0.9171 - val_loss: 0.3184\n",
            "Epoch 168/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8657 - loss: 0.3482 - val_accuracy: 0.8934 - val_loss: 0.3257\n",
            "Epoch 169/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9023 - loss: 0.2633 - val_accuracy: 0.9005 - val_loss: 0.3286\n",
            "Epoch 170/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9079 - loss: 0.2755 - val_accuracy: 0.8626 - val_loss: 0.3491\n",
            "Epoch 171/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8881 - loss: 0.3182 - val_accuracy: 0.8886 - val_loss: 0.3469\n",
            "Epoch 172/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9018 - loss: 0.3041 - val_accuracy: 0.8863 - val_loss: 0.3553\n",
            "Epoch 173/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9091 - loss: 0.2650 - val_accuracy: 0.9218 - val_loss: 0.3005\n",
            "Epoch 174/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9024 - loss: 0.2967 - val_accuracy: 0.8957 - val_loss: 0.3171\n",
            "Epoch 175/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9007 - loss: 0.2727 - val_accuracy: 0.9005 - val_loss: 0.3250\n",
            "Epoch 176/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8868 - loss: 0.2871 - val_accuracy: 0.8341 - val_loss: 0.4274\n",
            "Epoch 177/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9064 - loss: 0.2854 - val_accuracy: 0.9052 - val_loss: 0.2877\n",
            "Epoch 178/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9021 - loss: 0.2667 - val_accuracy: 0.9171 - val_loss: 0.3076\n",
            "Epoch 179/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9032 - loss: 0.2462 - val_accuracy: 0.8483 - val_loss: 0.3898\n",
            "Epoch 180/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9074 - loss: 0.2688 - val_accuracy: 0.8602 - val_loss: 0.3735\n",
            "Epoch 181/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9013 - loss: 0.2943 - val_accuracy: 0.9076 - val_loss: 0.3122\n",
            "Epoch 182/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8906 - loss: 0.3007 - val_accuracy: 0.9265 - val_loss: 0.2660\n",
            "Epoch 183/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8871 - loss: 0.3365 - val_accuracy: 0.8341 - val_loss: 0.4168\n",
            "Epoch 184/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9098 - loss: 0.2843 - val_accuracy: 0.9076 - val_loss: 0.3185\n",
            "Epoch 185/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9053 - loss: 0.2689 - val_accuracy: 0.9028 - val_loss: 0.3466\n",
            "Epoch 186/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9098 - loss: 0.2783 - val_accuracy: 0.9005 - val_loss: 0.3095\n",
            "Epoch 187/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8933 - loss: 0.3087 - val_accuracy: 0.8744 - val_loss: 0.3976\n",
            "Epoch 188/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8834 - loss: 0.3190 - val_accuracy: 0.8697 - val_loss: 0.3480\n",
            "Epoch 189/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8932 - loss: 0.2985 - val_accuracy: 0.8626 - val_loss: 0.3781\n",
            "Epoch 190/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8737 - loss: 0.3417 - val_accuracy: 0.8934 - val_loss: 0.3248\n",
            "Epoch 191/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9002 - loss: 0.2989 - val_accuracy: 0.9005 - val_loss: 0.3183\n",
            "Epoch 192/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9089 - loss: 0.2645 - val_accuracy: 0.8886 - val_loss: 0.3156\n",
            "Epoch 193/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9033 - loss: 0.2568 - val_accuracy: 0.8744 - val_loss: 0.3334\n",
            "Epoch 194/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.9047 - loss: 0.2874 - val_accuracy: 0.8720 - val_loss: 0.3732\n",
            "Epoch 195/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9192 - loss: 0.2538 - val_accuracy: 0.9052 - val_loss: 0.2993\n",
            "Epoch 196/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9139 - loss: 0.2315 - val_accuracy: 0.8697 - val_loss: 0.3750\n",
            "Epoch 197/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8897 - loss: 0.2934 - val_accuracy: 0.9028 - val_loss: 0.2860\n",
            "Epoch 198/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.8878 - loss: 0.2983 - val_accuracy: 0.8152 - val_loss: 0.4284\n",
            "Epoch 199/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9292 - loss: 0.2052 - val_accuracy: 0.9076 - val_loss: 0.3281\n",
            "Epoch 200/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9159 - loss: 0.2237 - val_accuracy: 0.9194 - val_loss: 0.2839\n",
            "Epoch 201/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9053 - loss: 0.2665 - val_accuracy: 0.8910 - val_loss: 0.3236\n",
            "Epoch 202/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9082 - loss: 0.2453 - val_accuracy: 0.8673 - val_loss: 0.3615\n",
            "Epoch 203/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9161 - loss: 0.2352 - val_accuracy: 0.8720 - val_loss: 0.3546\n",
            "Epoch 204/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8952 - loss: 0.2820 - val_accuracy: 0.9171 - val_loss: 0.2934\n",
            "Epoch 205/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9020 - loss: 0.2773 - val_accuracy: 0.8791 - val_loss: 0.3577\n",
            "Epoch 206/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9146 - loss: 0.2256 - val_accuracy: 0.8768 - val_loss: 0.3294\n",
            "Epoch 207/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8996 - loss: 0.2916 - val_accuracy: 0.9052 - val_loss: 0.3181\n",
            "Epoch 208/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9158 - loss: 0.2454 - val_accuracy: 0.9005 - val_loss: 0.3167\n",
            "Epoch 209/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8936 - loss: 0.2767 - val_accuracy: 0.9005 - val_loss: 0.2918\n",
            "Epoch 210/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9032 - loss: 0.2610 - val_accuracy: 0.9218 - val_loss: 0.2867\n",
            "Epoch 211/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9127 - loss: 0.2537 - val_accuracy: 0.8886 - val_loss: 0.3243\n",
            "Epoch 212/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9167 - loss: 0.2512 - val_accuracy: 0.8673 - val_loss: 0.3630\n",
            "Epoch 213/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9239 - loss: 0.2131 - val_accuracy: 0.8673 - val_loss: 0.3970\n",
            "Epoch 214/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9099 - loss: 0.2792 - val_accuracy: 0.8886 - val_loss: 0.3688\n",
            "Epoch 215/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8906 - loss: 0.2899 - val_accuracy: 0.9242 - val_loss: 0.2901\n",
            "Epoch 216/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9086 - loss: 0.2646 - val_accuracy: 0.9171 - val_loss: 0.3060\n",
            "Epoch 217/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9033 - loss: 0.2515 - val_accuracy: 0.9289 - val_loss: 0.3143\n",
            "Epoch 218/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.8955 - loss: 0.2748 - val_accuracy: 0.9123 - val_loss: 0.2896\n",
            "Epoch 219/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9135 - loss: 0.2482 - val_accuracy: 0.8839 - val_loss: 0.3413\n",
            "Epoch 220/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9069 - loss: 0.2603 - val_accuracy: 0.9028 - val_loss: 0.2874\n",
            "Epoch 221/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9141 - loss: 0.2279 - val_accuracy: 0.8815 - val_loss: 0.3539\n",
            "Epoch 222/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9145 - loss: 0.2645 - val_accuracy: 0.8815 - val_loss: 0.3254\n",
            "Epoch 223/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9198 - loss: 0.2227 - val_accuracy: 0.8673 - val_loss: 0.3638\n",
            "Epoch 224/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9166 - loss: 0.2722 - val_accuracy: 0.8578 - val_loss: 0.4004\n",
            "Epoch 225/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9174 - loss: 0.2213 - val_accuracy: 0.9171 - val_loss: 0.2776\n",
            "Epoch 226/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9250 - loss: 0.2184 - val_accuracy: 0.9147 - val_loss: 0.2661\n",
            "Epoch 227/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9129 - loss: 0.2422 - val_accuracy: 0.9100 - val_loss: 0.2684\n",
            "Epoch 228/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9197 - loss: 0.2608 - val_accuracy: 0.8839 - val_loss: 0.3078\n",
            "Epoch 229/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9115 - loss: 0.2484 - val_accuracy: 0.9289 - val_loss: 0.2597\n",
            "Epoch 230/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9238 - loss: 0.2315 - val_accuracy: 0.9265 - val_loss: 0.3118\n",
            "Epoch 231/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9052 - loss: 0.2875 - val_accuracy: 0.8578 - val_loss: 0.3778\n",
            "Epoch 232/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9149 - loss: 0.2358 - val_accuracy: 0.8815 - val_loss: 0.2962\n",
            "Epoch 233/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8969 - loss: 0.2687 - val_accuracy: 0.8981 - val_loss: 0.2850\n",
            "Epoch 234/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9110 - loss: 0.2293 - val_accuracy: 0.9052 - val_loss: 0.2804\n",
            "Epoch 235/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9029 - loss: 0.2728 - val_accuracy: 0.8886 - val_loss: 0.3069\n",
            "Epoch 236/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9157 - loss: 0.2458 - val_accuracy: 0.9028 - val_loss: 0.2836\n",
            "Epoch 237/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9232 - loss: 0.2183 - val_accuracy: 0.9313 - val_loss: 0.3046\n",
            "Epoch 238/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9319 - loss: 0.1901 - val_accuracy: 0.8957 - val_loss: 0.3289\n",
            "Epoch 239/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9232 - loss: 0.2083 - val_accuracy: 0.9218 - val_loss: 0.2541\n",
            "Epoch 240/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9174 - loss: 0.2158 - val_accuracy: 0.9242 - val_loss: 0.2868\n",
            "Epoch 241/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9206 - loss: 0.2185 - val_accuracy: 0.9052 - val_loss: 0.2979\n",
            "Epoch 242/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9070 - loss: 0.2483 - val_accuracy: 0.9194 - val_loss: 0.2793\n",
            "Epoch 243/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9110 - loss: 0.2513 - val_accuracy: 0.9313 - val_loss: 0.2972\n",
            "Epoch 244/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9270 - loss: 0.2283 - val_accuracy: 0.9123 - val_loss: 0.3027\n",
            "Epoch 245/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9184 - loss: 0.2372 - val_accuracy: 0.9123 - val_loss: 0.2794\n",
            "Epoch 246/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9157 - loss: 0.2454 - val_accuracy: 0.9028 - val_loss: 0.3080\n",
            "Epoch 247/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.9294 - loss: 0.2271 - val_accuracy: 0.9194 - val_loss: 0.2768\n",
            "Epoch 248/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9353 - loss: 0.1918 - val_accuracy: 0.9028 - val_loss: 0.3006\n",
            "Epoch 249/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9270 - loss: 0.2203 - val_accuracy: 0.9005 - val_loss: 0.2981\n",
            "Epoch 250/250\n",
            "\u001b[1m53/53\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.9271 - loss: 0.2056 - val_accuracy: 0.8957 - val_loss: 0.3365\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "       Angry       0.95      0.97      0.96        75\n",
            "        Calm       0.84      0.84      0.84        75\n",
            "     Disgust       0.81      0.56      0.67        39\n",
            "     Fearful       0.77      0.83      0.79        75\n",
            "       Happy       0.83      0.79      0.81        75\n",
            "     Neutral       0.61      0.82      0.70        38\n",
            "         Sad       0.81      0.76      0.79        75\n",
            "\n",
            "    accuracy                           0.81       452\n",
            "   macro avg       0.80      0.80      0.79       452\n",
            "weighted avg       0.82      0.81      0.81       452\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
        "\n",
        "# y_test: true labels (label encoded)\n",
        "# y_pred: predicted labels (label encoded)\n",
        "\n",
        "# If your true labels are one-hot encoded, convert them to integers\n",
        "# y_test = np.argmax(y_test_cat, axis=1)\n",
        "\n",
        "# 1. Overall accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\" Overall Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# 2. F1 Score (macro average)\n",
        "f1_macro = f1_score(y_test, y_pred, average='macro')\n",
        "print(f\" Macro-averaged F1 Score: {f1_macro:.4f}\")\n",
        "\n",
        "# 3. Full classification report\n",
        "target_names = le_emotion.classes_  # use label encoder to get original class names\n",
        "report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)\n",
        "df_report = pd.DataFrame(report).transpose()\n",
        "\n",
        "# Show only per-class rows (filter out avg/accuracy rows if needed)\n",
        "df_per_class = df_report.loc[target_names]\n",
        "print(\"\\n Per-Class Metrics (Precision, Recall, F1-score, Support):\")\n",
        "print(df_per_class[['precision', 'recall', 'f1-score', 'support']])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SXA1ixdNkkV0",
        "outputId": "cfb6ae21-4201-4016-909d-e9ab16806acb"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Overall Accuracy: 0.8119\n",
            " Macro-averaged F1 Score: 0.7933\n",
            "\n",
            " Per-Class Metrics (Precision, Recall, F1-score, Support):\n",
            "         precision    recall  f1-score  support\n",
            "Angry     0.948052  0.973333  0.960526     75.0\n",
            "Calm      0.840000  0.840000  0.840000     75.0\n",
            "Disgust   0.814815  0.564103  0.666667     39.0\n",
            "Fearful   0.765432  0.826667  0.794872     75.0\n",
            "Happy     0.830986  0.786667  0.808219     75.0\n",
            "Neutral   0.607843  0.815789  0.696629     38.0\n",
            "Sad       0.814286  0.760000  0.786207     75.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Model Training with ML Models**"
      ],
      "metadata": {
        "id": "R466VA6TFIcJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Intializing Models\n",
        "models={\"SVC\":SVC(kernel='rbf'),\"Logistic Regression\":LogisticRegression(),\"Bernouli ALgorithm\":BernoulliNB(),\"K Nearest Neighbor\":KNeighborsClassifier(),\n",
        "        \"Decision Tree\":DecisionTreeClassifier(),\"Random Forest\":RandomForestClassifier(),\"Gradient Boost\":GradientBoostingClassifier(),\n",
        "        \"Adaboost\":AdaBoostClassifier(),\"XGBoost\":XGBClassifier()}\n",
        "\n",
        "for i in range(len(models)):\n",
        "  model=list(models.values())[i]\n",
        "  model.fit(X_train_bal,y_train_bal)\n",
        "\n",
        "  ## Making Predictions\n",
        "  y_train_pred=model.predict(X_train_bal)\n",
        "  y_test_pred=model.predict(X_test_scaled)\n",
        "\n",
        "  ## Finding training set performance.\n",
        "  model_train_accuracy=accuracy_score(y_train_bal,y_train_pred)\n",
        "  model_train_precision=precision_score(y_train_bal,y_train_pred,average='weighted')\n",
        "  model_train_recall=recall_score(y_train_bal,y_train_pred,average='weighted')\n",
        "  model_train_f1=f1_score(y_train_bal,y_train_pred,average='weighted')\n",
        "\n",
        "\n",
        "  ## Finding training set performance.\n",
        "  model_test_accuracy=accuracy_score(y_test,y_test_pred)\n",
        "  model_test_precision=precision_score(y_test,y_test_pred,average='weighted')\n",
        "  model_test_recall=recall_score(y_test,y_test_pred,average='weighted')\n",
        "  model_test_f1=f1_score(y_test,y_test_pred,average='weighted')\n",
        "\n",
        "\n",
        "  # Printing\n",
        "\n",
        "  print(list(models.keys())[i])  ##Printing Model Name( Stored as keys )\n",
        "\n",
        "  print('Model performance for Training set')\n",
        "  print('-Accuracy: {:.4f}'.format(model_train_accuracy))\n",
        "  print('-Precision: {:.4f}'.format(model_train_precision))\n",
        "  print('-Recall: {:.4f}'.format(model_train_recall))\n",
        "  print('-F1 Score: {:.4f}'.format(model_train_f1))\n",
        "\n",
        "\n",
        "  print(\"-\"*50)\n",
        "\n",
        "  print('Model performance for Test set')\n",
        "  print('-Accuracy: {:.4f}'.format(model_test_accuracy))\n",
        "  print('-Precision: {:.4f}'.format(model_test_precision))\n",
        "  print('-Recall: {:.4f}'.format(model_test_recall))\n",
        "  print('-F1 Score: {:.4f}'.format(model_test_f1))\n",
        "\n",
        "\n",
        "  print(\"<>\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXIv8ui8CNUK",
        "outputId": "52449710-3c22-4199-eb4a-ceafb25613fb"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVC\n",
            "Model performance for Training set\n",
            "-Accuracy: 0.7499\n",
            "-Precision: 0.7718\n",
            "-Recall: 0.7499\n",
            "-F1 Score: 0.7485\n",
            "--------------------------------------------------\n",
            "Model performance for Test set\n",
            "-Accuracy: 0.6482\n",
            "-Precision: 0.6833\n",
            "-Recall: 0.6482\n",
            "-F1 Score: 0.6512\n",
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
            "Logistic Regression\n",
            "Model performance for Training set\n",
            "-Accuracy: 0.7646\n",
            "-Precision: 0.7640\n",
            "-Recall: 0.7646\n",
            "-F1 Score: 0.7634\n",
            "--------------------------------------------------\n",
            "Model performance for Test set\n",
            "-Accuracy: 0.6571\n",
            "-Precision: 0.6610\n",
            "-Recall: 0.6571\n",
            "-F1 Score: 0.6568\n",
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
            "Bernouli ALgorithm\n",
            "Model performance for Training set\n",
            "-Accuracy: 0.3351\n",
            "-Precision: 0.3506\n",
            "-Recall: 0.3351\n",
            "-F1 Score: 0.2851\n",
            "--------------------------------------------------\n",
            "Model performance for Test set\n",
            "-Accuracy: 0.3363\n",
            "-Precision: 0.3549\n",
            "-Recall: 0.3363\n",
            "-F1 Score: 0.2654\n",
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
            "K Nearest Neighbor\n",
            "Model performance for Training set\n",
            "-Accuracy: 0.8239\n",
            "-Precision: 0.8331\n",
            "-Recall: 0.8239\n",
            "-F1 Score: 0.8204\n",
            "--------------------------------------------------\n",
            "Model performance for Test set\n",
            "-Accuracy: 0.6150\n",
            "-Precision: 0.6618\n",
            "-Recall: 0.6150\n",
            "-F1 Score: 0.6124\n",
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
            "Decision Tree\n",
            "Model performance for Training set\n",
            "-Accuracy: 1.0000\n",
            "-Precision: 1.0000\n",
            "-Recall: 1.0000\n",
            "-F1 Score: 1.0000\n",
            "--------------------------------------------------\n",
            "Model performance for Test set\n",
            "-Accuracy: 0.4845\n",
            "-Precision: 0.4875\n",
            "-Recall: 0.4845\n",
            "-F1 Score: 0.4842\n",
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
            "Random Forest\n",
            "Model performance for Training set\n",
            "-Accuracy: 1.0000\n",
            "-Precision: 1.0000\n",
            "-Recall: 1.0000\n",
            "-F1 Score: 1.0000\n",
            "--------------------------------------------------\n",
            "Model performance for Test set\n",
            "-Accuracy: 0.6947\n",
            "-Precision: 0.6969\n",
            "-Recall: 0.6947\n",
            "-F1 Score: 0.6938\n",
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
            "Gradient Boost\n",
            "Model performance for Training set\n",
            "-Accuracy: 0.9957\n",
            "-Precision: 0.9958\n",
            "-Recall: 0.9957\n",
            "-F1 Score: 0.9957\n",
            "--------------------------------------------------\n",
            "Model performance for Test set\n",
            "-Accuracy: 0.7058\n",
            "-Precision: 0.7181\n",
            "-Recall: 0.7058\n",
            "-F1 Score: 0.7070\n",
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
            "Adaboost\n",
            "Model performance for Training set\n",
            "-Accuracy: 0.3911\n",
            "-Precision: 0.4094\n",
            "-Recall: 0.3911\n",
            "-F1 Score: 0.3806\n",
            "--------------------------------------------------\n",
            "Model performance for Test set\n",
            "-Accuracy: 0.3142\n",
            "-Precision: 0.3083\n",
            "-Recall: 0.3142\n",
            "-F1 Score: 0.2936\n",
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
            "XGBoost\n",
            "Model performance for Training set\n",
            "-Accuracy: 1.0000\n",
            "-Precision: 1.0000\n",
            "-Recall: 1.0000\n",
            "-F1 Score: 1.0000\n",
            "--------------------------------------------------\n",
            "Model performance for Test set\n",
            "-Accuracy: 0.7721\n",
            "-Precision: 0.7735\n",
            "-Recall: 0.7721\n",
            "-F1 Score: 0.7717\n",
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Not upto the mark result we got in ANN models"
      ],
      "metadata": {
        "id": "V6zoiEnCyBKt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tuning best ML models"
      ],
      "metadata": {
        "id": "i6_rGmV7Gu2d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Defining parameter grid for our different models.\n",
        "rf_params={\"max_depth\":[8,10,15,17,None],\n",
        "           \"max_features\":[5,7,\"auto\",8],\n",
        "            \"min_samples_split\": [2, 8, 15, 20],\n",
        "            \"n_estimators\": [100, 200, 500, 1000],\n",
        "           \"criterion\":['gini','entropy','log_loss']}\n",
        "gb_params={\"learning_rate\":[0.1,0.01,0.2],\n",
        "           \"n_estimators\":[100,200,300,400],\n",
        "           \"criterion\":['friedman_mse','squared_error'],\n",
        "           \"min_samples_split\":[2,4,6]}\n",
        "xgb_params={\"learning_rate\":[0.01,0.1,0.2],\n",
        "            \"max_depth\":[5,8,12,20,30],\n",
        "            \"n_estimator\":[100,200,300,400],\n",
        "            \"colsample_bytree\":[0.5,0.8,1,0.3,0.4]}"
      ],
      "metadata": {
        "id": "z4aIg_-0HTEh"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Model list for hyper parameter tuning.\n",
        "randomcv_models = [(\"XGB\",XGBClassifier(),xgb_params)]"
      ],
      "metadata": {
        "id": "BVDMSIzgwrak"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "model_param={}\n",
        "for name,model,params in randomcv_models:\n",
        "  random=RandomizedSearchCV(estimator=model,\n",
        "                            param_distributions=params,\n",
        "                            cv=3,\n",
        "                            verbose=2,\n",
        "                            n_jobs=-1)\n",
        "  random.fit(X_train,y_train)\n",
        "  model_param[name]=random.best_params_\n",
        "\n",
        "for model_name in model_param:\n",
        "  print(f\"---------------- Best Params for {model_name} -------------------\")\n",
        "  print(model_param[model_name])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBSG_nZIwrNQ",
        "outputId": "27bf2d5a-b25f-436a-c1a9-adf88355a49f"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
            "---------------- Best Params for XGB -------------------\n",
            "{'n_estimator': 100, 'max_depth': 12, 'learning_rate': 0.2, 'colsample_bytree': 0.3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models={\n",
        "\n",
        "    \"Random Forest\":RandomForestClassifier(n_estimators= 200, min_samples_split= 2,max_features= 5, max_depth= None, criterion= 'log_loss'),\n",
        "    \"Gradient Boost\":GradientBoostingClassifier(n_estimators=400, min_samples_split= 2, learning_rate= 0.2,criterion= 'squared_error'),\n",
        "    \"XG Boost\":XGBClassifier(n_estimator= 100, max_depth= 12, learning_rate= 0.2,colsample_bytree= 0.3)\n",
        "}\n",
        "\n",
        "\n",
        "\n",
        "for i in range(len(models)):\n",
        "  model=list(models.values())[i]\n",
        "  model.fit(X_train,y_train)\n",
        "\n",
        "  ## Making Predictions\n",
        "  y_train_pred=model.predict(X_train)\n",
        "  y_test_pred=model.predict(X_test)\n",
        "\n",
        "  ## Finding training set performance.\n",
        "  model_train_accuracy=accuracy_score(y_train,y_train_pred)\n",
        "  model_train_precision=precision_score(y_train,y_train_pred,average='weighted')\n",
        "  model_train_recall=recall_score(y_train,y_train_pred,average='weighted')\n",
        "  model_train_f1=f1_score(y_train,y_train_pred,average='weighted')\n",
        "\n",
        "\n",
        "  ## Finding training set performance.\n",
        "  model_test_accuracy=accuracy_score(y_test,y_test_pred)\n",
        "  model_test_precision=precision_score(y_test,y_test_pred,average='weighted')\n",
        "  model_test_recall=recall_score(y_test,y_test_pred,average='weighted')\n",
        "  model_test_f1=f1_score(y_test,y_test_pred,average='weighted')\n",
        "\n",
        "\n",
        "  # Printing\n",
        "\n",
        "  print(list(models.keys())[i])  ##Printing Model Name( Stored as keys )\n",
        "\n",
        "  print('Model performance for Training set')\n",
        "  print('-Accuracy: {:.4f}'.format(model_train_accuracy))\n",
        "  print('-Precision: {:.4f}'.format(model_train_precision))\n",
        "  print('-Recall: {:.4f}'.format(model_train_recall))\n",
        "  print('-F1 Score: {:.4f}'.format(model_train_f1))\n",
        "\n",
        "\n",
        "  print(\"-\"*50)\n",
        "\n",
        "  print('Model performance for Test set')\n",
        "  print('-Accuracy: {:.4f}'.format(model_test_accuracy))\n",
        "  print('-Precision: {:.4f}'.format(model_test_precision))\n",
        "  print('-Recall: {:.4f}'.format(model_test_recall))\n",
        "  print('-F1 Score: {:.4f}'.format(model_test_f1))\n",
        "\n",
        "\n",
        "  print(\"<>\"*50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emAgdAHOwrJ6",
        "outputId": "ee5b168e-5c90-4d4d-a301-1f8556da9e9c"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest\n",
            "Model performance for Training set\n",
            "-Accuracy: 1.0000\n",
            "-Precision: 1.0000\n",
            "-Recall: 1.0000\n",
            "-F1 Score: 1.0000\n",
            "--------------------------------------------------\n",
            "Model performance for Test set\n",
            "-Accuracy: 0.6770\n",
            "-Precision: 0.6843\n",
            "-Recall: 0.6770\n",
            "-F1 Score: 0.6732\n",
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
            "Gradient Boost\n",
            "Model performance for Training set\n",
            "-Accuracy: 1.0000\n",
            "-Precision: 1.0000\n",
            "-Recall: 1.0000\n",
            "-F1 Score: 1.0000\n",
            "--------------------------------------------------\n",
            "Model performance for Test set\n",
            "-Accuracy: 0.7699\n",
            "-Precision: 0.7691\n",
            "-Recall: 0.7699\n",
            "-F1 Score: 0.7687\n",
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n",
            "XG Boost\n",
            "Model performance for Training set\n",
            "-Accuracy: 1.0000\n",
            "-Precision: 1.0000\n",
            "-Recall: 1.0000\n",
            "-F1 Score: 1.0000\n",
            "--------------------------------------------------\n",
            "Model performance for Test set\n",
            "-Accuracy: 0.7500\n",
            "-Precision: 0.7511\n",
            "-Recall: 0.7500\n",
            "-F1 Score: 0.7494\n",
            "<><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><><>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cB4CzGjgXuGJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}